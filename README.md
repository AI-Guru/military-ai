# military-ai
A collection of resources about AI in the military

## Science

## Media

### 2024.11.24 - Meta AI is ready for war

[Source](https://www.theverge.com/2024/11/4/24287951/meta-ai-llama-war-us-government-national-security)

Meta announced it's now allowing US government agencies and military contractors to use its open-source Llama AI model for national security applications, despite previous restrictions in its acceptable use policy against using Llama 3 for "military, warfare, nuclear industries or applications, espionage."

The company is partnering with Amazon, Microsoft, IBM, Lockheed Martin, Oracle and others to make Llama available to the government. Meta says this will enable the US military to use Llama for tasks like streamlining logistics, tracking terrorist financing, and strengthening cyber defenses.

Some partners have already begun implementing the technology - Oracle is using Llama to help aircraft technicians with maintenance by synthesizing repair documents, while Lockheed Martin is using it for code generation and data analysis.

This policy shift comes after reports that Chinese researchers used Meta's earlier Llama 2 model to build an AI system for China's military. Meta emphasized the importance of the US leading in the AI race, stating it's in "both America and the wider democratic world's interest for American open source models to excel and succeed over models from China and elsewhere."

The article notes other AI companies are also engaging with military applications - US Africa Command purchased cloud computing services from Microsoft that include access to OpenAI's tools, and Google DeepMind has a cloud computing contract with the Israeli government.


### 2025.03.06 - Revealed: Israeli military creating ChatGPT-like tool using vast collection of Palestinian surveillance data

[Source](https://www.theguardian.com/world/2025/mar/06/israel-military-ai-surveillance)

The Guardian has revealed that Israel's military intelligence agency, Unit 8200, is developing a ChatGPT-like AI tool using a vast database of intercepted Palestinian communications. This elite eavesdropping unit trained their large language model (LLM) on approximately 100 billion words from intercepted Arabic conversations to understand colloquial dialects rather than formal written Arabic.

Development of this system accelerated after October 2023 when the Gaza war began, with the project benefiting from reservists with AI expertise from major tech companies like Google, Microsoft, and Meta. The system aims to create a sophisticated chatbot capable of analyzing surveillance data and answering questions about monitored individuals.

The LLM builds upon existing AI tools used by the IDF such as "The Gospel" and "Lavender," which help identify potential targets, enhancing the military's ability to process massive volumes of intercepted communications. Sources indicate the technology has expanded surveillance capabilities beyond security threats to monitor activists and civilian activities, with AI models reportedly increasing arrests in the West Bank by identifying Palestinians expressing dissent.

Human rights organizations warn these AI systems can amplify biases and produce errors, with critics arguing the model violates Palestinians' privacy rights. While intelligence agencies worldwide are exploring AI capabilities, Israel appears to be taking greater risks in deployment. The technology demonstrates how military organizations are adapting commercial AI advances for surveillance purposes, raising important questions about privacy, surveillance ethics, and the potential for consequential errors in military AI applications.
