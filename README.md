# Artificial Intelligence in the Military - Dr. Tristan Behrens

Let us connect: [LinkedIn](https://www.linkedin.com/in/dr-tristan-behrens-734967a2/)

## Science

### 2024.07.03 On Large Language Models in National Security Applications

[Source](https://arxiv.org/abs/2407.03453)

This article examines the integration of large language models (LLMs) like GPT-4 into national security operations, highlighting both opportunities and challenges. LLMs offer substantial benefits for national security organizations, including automating information processing, enhancing data analysis, and improving decision-making efficiency. When coupled with decision-theoretic principles and Bayesian reasoning, these models can facilitate the transition from data to actionable decisions with reduced manpower requirements.

The US Department of Defense is already implementing LLMs in various applications, such as the USAF's use for wargaming and automatic summarization of intelligence reports. These applications demonstrate how LLMs can streamline operations and support tactical and strategic decision-making processes. The integration of LLMs with probabilistic and statistical methods can provide more robust threat predictions and improve operational readiness through personalized training experiences.

However, significant risks accompany these benefits. The article identifies hallucinations (generating false information), data privacy concerns, and vulnerability to adversarial attacks as critical challenges, particularly in high-stakes environments where information accuracy is crucial. These risks necessitate rigorous safeguards and continuous scrutiny of AI security protocols.

The broader implications extend to international relations and geopolitics, with adversarial nations potentially leveraging LLMs for disinformation campaigns and cyber operations. Despite showing "sparks" of artificial general intelligence, the article argues LLMs are currently best suited for supporting roles rather than leading strategic decisions.

The authors advocate for a cautious, calculated approach to LLM integration, guided by responsible AI frameworks. They emphasize the importance of continued collaboration between defense, academic, and commercial entities to realize benefits while mitigating risks, ultimately enabling national security professionals to establish strategic advantage in an increasingly contested technological landscape.


### 2024.02.01 - COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations 

[Source](https://arxiv.org/abs/2402.01786)

This research introduces COA-GPT, an innovative algorithm that uses Large Language Models (LLMs) to generate military Courses of Action (COAs) rapidly and efficiently. The system addresses the traditionally time-consuming nature of military planning by incorporating military doctrine and expertise into LLMs through in-context learning.

COA-GPT allows commanders to input mission information in both text and image formats and quickly receive strategically aligned action plans. A key advantage is that it produces initial COAs within seconds while enabling real-time refinement based on commander feedback.

The study evaluated COA-GPT in a militarized version of StarCraft II, comparing it against reinforcement learning algorithms. Results demonstrated that COA-GPT generated more strategically sound plans more quickly than alternative approaches. The system showed superior performance in developing COAs aligned with commander intent and exhibited enhanced adaptability when incorporating human feedback.

Unlike other approaches, COA-GPT doesn't require extensive pre-training, making it suitable for rapid deployment across diverse military scenarios. Its ability to quickly adapt and update plans during missions represents a potentially transformative advancement for military command and control operations, particularly for addressing planning discrepancies and capitalizing on emerging opportunities.

The research concludes that COA-GPT could reshape military planning and decision-making for increasingly complex and dynamic future battlefields, facilitating faster and more agile command decisions while maintaining strategic advantage in modern warfare contexts.


## Media

### 2024.11.24 - Meta AI is ready for war

[Source](https://www.theverge.com/2024/11/4/24287951/meta-ai-llama-war-us-government-national-security)

Meta announced it's now allowing US government agencies and military contractors to use its open-source Llama AI model for national security applications, despite previous restrictions in its acceptable use policy against using Llama 3 for "military, warfare, nuclear industries or applications, espionage."

The company is partnering with Amazon, Microsoft, IBM, Lockheed Martin, Oracle and others to make Llama available to the government. Meta says this will enable the US military to use Llama for tasks like streamlining logistics, tracking terrorist financing, and strengthening cyber defenses.

Some partners have already begun implementing the technology - Oracle is using Llama to help aircraft technicians with maintenance by synthesizing repair documents, while Lockheed Martin is using it for code generation and data analysis.

This policy shift comes after reports that Chinese researchers used Meta's earlier Llama 2 model to build an AI system for China's military. Meta emphasized the importance of the US leading in the AI race, stating it's in "both America and the wider democratic world's interest for American open source models to excel and succeed over models from China and elsewhere."

The article notes other AI companies are also engaging with military applications - US Africa Command purchased cloud computing services from Microsoft that include access to OpenAI's tools, and Google DeepMind has a cloud computing contract with the Israeli government.

### 2025.07.10 Department of the Air Force launches NIPRGPT 

[Source](https://www.af.mil/News/Article-Display/Article/3800809/department-of-the-air-force-launches-niprgpt/)

The Department of the Air Force has launched NIPRGPT, an experimental AI chatbot that allows personnel to use Generative AI on the Non-classified Internet Protocol Router Network. This CAC-enabled tool is part of the DAF's broader initiative to provide Airmen, Guardians, civilian employees, and contractors with access to AI technology while maintaining appropriate security measures.

NIPRGPT is being offered through the Dark Saber software platform developed at the Air Force Research Laboratory Information Directorate in Rome, New York. It enables users to have human-like conversations for completing various tasks, including drafting correspondence, background papers, and code, all at no additional cost to units or users.

Venice Goodwine, DAF chief information officer, emphasized that now is the time to provide personnel with tools to develop AI skills, while Chandra Donelson, acting chief data and AI officer, noted that "technology is learned by doing" and that insights from users will inform future policy and investment decisions.

The experiment aims to gather data on computational efficiency, resource utilization, and security compliance to understand practical applications and challenges of Generative AI. The platform includes feedback mechanisms to help develop governance policies and guide vendor conversations as the DAF incorporates these tools into its operations.

Alexis Bonnell, AFRL chief information officer, described NIPRGPT as a "critical bridge" while more powerful commercial tools navigate security parameters. CAC holders can register at https://niprgpt.mil, though the system has limited capacity during the experimental phase.


### 2024.03.06 - Revealed: Israeli military creating ChatGPT-like tool using vast collection of Palestinian surveillance data

[Source](https://www.theguardian.com/world/2025/mar/06/israel-military-ai-surveillance)

The Guardian has revealed that Israel's military intelligence agency, Unit 8200, is developing a ChatGPT-like AI tool using a vast database of intercepted Palestinian communications. This elite eavesdropping unit trained their large language model (LLM) on approximately 100 billion words from intercepted Arabic conversations to understand colloquial dialects rather than formal written Arabic.

Development of this system accelerated after October 2023 when the Gaza war began, with the project benefiting from reservists with AI expertise from major tech companies like Google, Microsoft, and Meta. The system aims to create a sophisticated chatbot capable of analyzing surveillance data and answering questions about monitored individuals.

The LLM builds upon existing AI tools used by the IDF such as "The Gospel" and "Lavender," which help identify potential targets, enhancing the military's ability to process massive volumes of intercepted communications. Sources indicate the technology has expanded surveillance capabilities beyond security threats to monitor activists and civilian activities, with AI models reportedly increasing arrests in the West Bank by identifying Palestinians expressing dissent.

Human rights organizations warn these AI systems can amplify biases and produce errors, with critics arguing the model violates Palestinians' privacy rights. While intelligence agencies worldwide are exploring AI capabilities, Israel appears to be taking greater risks in deployment. The technology demonstrates how military organizations are adapting commercial AI advances for surveillance purposes, raising important questions about privacy, surveillance ethics, and the potential for consequential errors in military AI applications.
